{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考：统计学习方法，西瓜书，Machine Learnig with python，https://www.python-course.eu/Decision_Trees.php"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意几点：连续特征处理，预测问题或者说回归问题（连续性目标特征）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 决策树（Decision tree）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 熵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "熵表示随机变量不确定性的度量。离散随机变量X的概率分布为,$P(X=x_i)=p_i,i=1,2,3...,n$.则随机变量X的熵可以定义为：$$H(p)=-\\sum_{i=1}^np_ilog_2(p_i)$$$$0\\leq H(p)\\leq log_2(n)$$熵越大，随机变量的不确定性就越大.当随机变量的取任何值概率都相等时，也就是$p_i=\\frac{1}{n}$时，熵最大.此时可以知道$H(p)=-n\\times\\frac{1}{n}\\times log_2(\\frac{1}{n})=log_2(n)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 条件熵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们知道条件概率为$P(Y=y_i|X=x_i)$,表示在已知$X=x_i$条件下$Y=y_i$的概率.$\\quad$则条件熵定义为在已知随机变量$X$的条件下，随机变量Y的不确定性，表示为$H(Y|X)$:$$H(Y|X)=-\\sum_{i=1}^n p_iH(Y|X=x_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 信息增益"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "特征A对于训练数据D的信息增益表示为$g(D,A)$：$$g(D,A)=H(D)-H(D|A)$$H(D)表示原始数据分类的不确定性,$H(D|A)$表示特征A给定条件下数据集D分类的不确定性.$g(D,A)$就表示给定特征A后数据集D不确定性减小的程度.对于数据集$D$和特征$A$有：$$H(D)=-\\sum_{i=1}^K\\frac{|C_k|}{|D|}log_2\\frac{|C_k|}{|D|}$$,这里$|C_k|$表示类别$C_k$的数量.$$H(D|A)=\\sum_{i=1}^n\\frac{|D_i|}{|D|}H(D_i)=\\sum_{i=1}^n\\frac{|D_i|}{|D|}\\sum_{k=1}^K\\frac{|D_{ik}|}{|D_i|}log_2(\\frac{|D_{ik}|}{|D_i|})$$这里$n$表示特征$A$的可取值数量."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 信息增益比"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义：特征A对训练数据集D的信息增益比$g_R(D,A)$定义为其信息增益$g(D,A)$与训练数据D关于特征A的值的熵$H_A(D)$值比，即：$$g_R(D,A)=\\frac{g(D,A)}{H_A(D)}$$,其中$H_A(D)=-\\sum_{i=1}^n\\frac{|D_i|}{|D|}log_2\\frac{|D_i|}{|D|}$,$n$是特征$A$取值个数."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基尼指数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义：分类问题假设有$K$个类，样本点属于第$k$类的概率为$p_k$,则概率分布的基尼指数定义为$$Gini(p)=\\sum_{k=1}^Kp_k(1-p_k)=1-\\sum_{k=1}^Kp^2_k$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于二分类问题，若样本点属于第一个类的概率是p,则概率分布的基尼指数为$$Gini(p)=2p(1-p)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于给定样本集合$D$,其基尼指数为：$$Gini(D)=1-\\sum_{k=1}^K(\\frac{C_k}{D})^2 （1）$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里，$C_k$是$D$中属于第$k$类的样本自己，$K$是类的个数."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果样本集合根据特征$A$是否取某一可能值$a$,被分割成$D_1$和$D_2$两个部分，即$$D_1=\\{(x,y)\\in D|A(x)=a\\},D_2=D-D_1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "则在特征$A$的条件下，集合$D$的基尼指数定义为:$$Gini(D,A)=\\frac{D_1}{D}Gini(D_1)+\\frac{D_2}{D}Gini(D_2)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基尼指数$Gini(D)$表示集合$D$的不确定性，基尼指数$G(D,A)$表示经$A=a$分割后集合$D$的不确定性.基尼指数越大，样本集合的不确定性也就越大.怎么理解：当种类数变多时（1）式中第二项会变小，这样会使基尼指数变大，这样也就是表示了不确定性越大."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 决策树生成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ID3：   \n",
    "输入：训练数据集$D$，特征集$A$，阈值$\\epsilon$;  \n",
    "输出：决策树$T$   \n",
    "1.若$D$中所有实例属于同一类$C_k$,则$T$为单节点树，并将类$C_k$作为该节点的类标记，返回T；   \n",
    "2.若$A=\\varnothing$,则返回单节点树，并将$D$中实例数最大的类$C_k$作为该节点的类标记，返回$T$；  \n",
    "3.否则，选择信息增益最大的特征$A_g$；  \n",
    "4.如果$A_g$信息增益小于阈值$\\epsilon$，则置$T$为单节点树，并将$D$中实例数最大的类$C_k$作为该节点的类标记，返回$T$；  \n",
    "5.否则，对$A_g$的每个可能值$a_i$,依$A_g=a_i$将$D$分为若干个非空子集$D_i$,将$D_i$中实例数最大的类作为标记，构建子节点，由节点及其子节点构成树$T$,返回$T$；  \n",
    "6.对第i个子节点，以$D_i$为训练集，以$A-\\{A_g\\}$为特征集，递归调用1-5步，得到子树，返回$T_i$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C45：  \n",
    "C45与ID3算法相似，但是使用的是信息增益比来选择特征，这是因为 **以信息增益比作为划分训练数据集的特征，存在偏向于选择取值较多的特征的问题.使用信息增益比可以对这一问题进行校正**. 这是因为$A$的取值很多的话$\\frac{|D_i|}{|D|}$会很小，这样会导致$H(D|A)$也会很小，这样信息增益就会很大.而信息增益比在信息增益的基础上除以了特征$A$的取值类别的熵，也就是$H_A(D)$就表示特征$A$的取值不确定性程度或者说取值复杂度，那么信息增益的基础上除以$H_A(D)$就可以抵消掉特征$A$的取值复杂度的影响."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 剪枝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "决策树剪枝通过最小化决策树整体的损失函数来实现."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CART"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "后面回归树一起"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 优点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不需要特征归一化处理；  \n",
    "可以做分类，也可以做回归；  \n",
    "可以建模非线性关系；  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 缺点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "若是连续特征，树可能会相当大；  \n",
    "决策树的一个缺点是要求训练数据中包含所有标签类，否则对于数据中没有出现过的标签类没有判别能力   \n",
    "数据微小变化可能导致不同的树；   \n",
    "若特征很多，而数据量少，那么树很容易过拟合；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### python实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>animal_name</th>\n",
       "      <th>hair</th>\n",
       "      <th>feathers</th>\n",
       "      <th>eggs</th>\n",
       "      <th>milk</th>\n",
       "      <th>airbone</th>\n",
       "      <th>aquatic</th>\n",
       "      <th>predator</th>\n",
       "      <th>toothed</th>\n",
       "      <th>backbone</th>\n",
       "      <th>breathes</th>\n",
       "      <th>venomous</th>\n",
       "      <th>fins</th>\n",
       "      <th>legs</th>\n",
       "      <th>tail</th>\n",
       "      <th>domestic</th>\n",
       "      <th>catsize</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aardvark</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>antelope</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bass</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bear</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>boar</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  animal_name  hair  feathers  eggs  milk  airbone  aquatic  predator  \\\n",
       "0    aardvark     1         0     0     1        0        0         1   \n",
       "1    antelope     1         0     0     1        0        0         0   \n",
       "2        bass     0         0     1     0        0        1         1   \n",
       "3        bear     1         0     0     1        0        0         1   \n",
       "4        boar     1         0     0     1        0        0         1   \n",
       "\n",
       "   toothed  backbone  breathes  venomous  fins  legs  tail  domestic  catsize  \\\n",
       "0        1         1         1         0     0     4     0         0        1   \n",
       "1        1         1         1         0     0     4     1         0        1   \n",
       "2        1         1         0         0     1     0     1         0        0   \n",
       "3        1         1         1         0     0     4     0         0        1   \n",
       "4        1         1         1         0     0     4     1         0        1   \n",
       "\n",
       "   class  \n",
       "0      1  \n",
       "1      1  \n",
       "2      4  \n",
       "3      1  \n",
       "4      1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint \n",
    "dataset=pd.read_csv(\"data/zoo.data\",names=[\"animal_name\",\"hair\",\"feathers\",\"eggs\",\"milk\",\n",
    "                                       \"airbone\",\"aquatic\",\"predator\",\"toothed\",\"backbone\",\"breathes\",\"venomous\",\"fins\",\"legs\"\n",
    "                                       ,\"tail\",\"domestic\",\"catsize\",\"class\"])##若有数据没有columns可以使用names来添加\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hair</th>\n",
       "      <th>feathers</th>\n",
       "      <th>eggs</th>\n",
       "      <th>milk</th>\n",
       "      <th>airbone</th>\n",
       "      <th>aquatic</th>\n",
       "      <th>predator</th>\n",
       "      <th>toothed</th>\n",
       "      <th>backbone</th>\n",
       "      <th>breathes</th>\n",
       "      <th>venomous</th>\n",
       "      <th>fins</th>\n",
       "      <th>legs</th>\n",
       "      <th>tail</th>\n",
       "      <th>domestic</th>\n",
       "      <th>catsize</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hair  feathers  eggs  milk  airbone  aquatic  predator  toothed  backbone  \\\n",
       "0     1         0     0     1        0        0         1        1         1   \n",
       "1     1         0     0     1        0        0         0        1         1   \n",
       "2     0         0     1     0        0        1         1        1         1   \n",
       "3     1         0     0     1        0        0         1        1         1   \n",
       "4     1         0     0     1        0        0         1        1         1   \n",
       "\n",
       "   breathes  venomous  fins  legs  tail  domestic  catsize  class  \n",
       "0         1         0     0     4     0         0        1      1  \n",
       "1         1         0     0     4     1         0        1      1  \n",
       "2         0         0     1     0     1         0        0      4  \n",
       "3         1         0     0     4     0         0        1      1  \n",
       "4         1         0     0     4     1         0        1      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset=dataset.drop(\"animal_name\",axis=1)#去掉列\n",
    "dataset.head()\n",
    "#dataset.loc[set(range(0,101))-set([9,100,2])]#去掉行\n",
    "#dataset[[\"hair\",\"eggs\"]].iloc[[1,2,3,6]]#去掉行和列\n",
    "#np.unique(dataset[[\"hair\",\"eggs\"]].iloc[[1,2,3,6]])#去掉重复项\n",
    "#p.unique(dataset[\"tail\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(target_col):\n",
    "    elements,counts = np.unique(target_col,return_counts = True)\n",
    "    entropy = np.sum([(-counts[i]/np.sum(counts))*np.log2(counts[i]/np.sum(counts)) for i in range(len(elements))])\n",
    "    return entropy\n",
    "def InfoGain(data,split_attribute_name,target_name=\"class\"):\n",
    "    total_entropy = entropy(data[target_name])\n",
    "    vals,counts= np.unique(data[split_attribute_name],return_counts=True)\n",
    "    Weighted_Entropy = np.sum([(counts[i]/np.sum(counts))*entropy(data.where(data[split_attribute_name]==vals[i]).dropna()[target_name]) for i in range(len(vals))])\n",
    "    Information_Gain = total_entropy - Weighted_Entropy\n",
    "    return Information_Gain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ID3(data,originaldata,features,target_attribute_name=\"class\",parent_node_class = None):    \n",
    "    if len(np.unique(data[target_attribute_name])) <= 1:#也就是只有一个类别\n",
    "        return np.unique(data[target_attribute_name])[0]#返回该类\n",
    "    elif len(data)==0:\n",
    "        return np.unique(originaldata[target_attribute_name])[np.argmax(np.unique(originaldata[target_attribute_name],return_counts=True)[1])]\n",
    "    elif len(features) ==0:\n",
    "        return parent_node_class\n",
    "    else:\n",
    "        parent_node_class = np.unique(data[target_attribute_name])[np.argmax(np.unique(data[target_attribute_name],return_counts=True)[1])]\n",
    "    item_values = [InfoGain(data,feature,target_attribute_name) for feature in features] #Return the information gain values for the features in the dataset\n",
    "    best_feature_index = np.argmax(item_values)\n",
    "    best_feature = features[best_feature_index]\n",
    "    tree = {best_feature:{}}\n",
    "    features = [i for i in features if i != best_feature]\n",
    "    for value in np.unique(data[best_feature]):\n",
    "            value = value\n",
    "            sub_data = data.where(data[best_feature] == value).dropna()\n",
    "            subtree = ID3(sub_data,dataset,features,target_attribute_name,parent_node_class)\n",
    "            tree[best_feature][value] = subtree\n",
    "            #print(tree)\n",
    "    return(tree)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(query,tree,default = 1):\n",
    "    for key in list(query.keys()):\n",
    "        if key in list(tree.keys()):\n",
    "            #2.\n",
    "            try:\n",
    "                result = tree[key][query[key]] \n",
    "            except:\n",
    "                return default\n",
    "            #3.\n",
    "            result = tree[key][query[key]]\n",
    "            #4.\n",
    "            if isinstance(result,dict):\n",
    "                return predict(query,result)\n",
    "            else:\n",
    "                return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'legs': {0: {'fins': {0.0: {'toothed': {0.0: 7.0, 1.0: 3.0}},\n",
      "                       1.0: {'eggs': {0.0: 1.0, 1.0: 4.0}}}},\n",
      "          2: {'hair': {0.0: 2.0, 1.0: 1.0}},\n",
      "          4: {'hair': {0.0: {'toothed': {0.0: 7.0, 1.0: 5.0}}, 1.0: 1.0}},\n",
      "          6: {'aquatic': {0.0: 6.0, 1.0: 7.0}},\n",
      "          8: 7.0}}\n"
     ]
    }
   ],
   "source": [
    "def train_test_split(dataset):\n",
    "    training_data = dataset.iloc[:80].reset_index(drop=True)\n",
    "    testing_data = dataset.iloc[80:].reset_index(drop=True)\n",
    "    return training_data,testing_data\n",
    "training_data = train_test_split(dataset)[0]\n",
    "testing_data = train_test_split(dataset)[1] \n",
    "tree = ID3(training_data,training_data,training_data.columns[:-1])\n",
    "pprint(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction accuracy is:  85.71428571428571 %\n"
     ]
    }
   ],
   "source": [
    "def test(data,tree):\n",
    "    #Create new query instances by simply removing the target feature column from the original dataset and \n",
    "    #convert it to a dictionary\n",
    "    queries = data.to_dict(orient = \"records\")\n",
    "    \n",
    "    #Create a empty DataFrame in whose columns the prediction of the tree are stored\n",
    "    predicted = pd.DataFrame(columns=[\"predicted\"]) \n",
    "    \n",
    "    #Calculate the prediction accuracy\n",
    "    for i in range(len(data)):\n",
    "        predicted.loc[i,\"predicted\"] = predict(queries[i],tree,1.0) \n",
    "    print('The prediction accuracy is: ',(np.sum(predicted[\"predicted\"] == data[\"class\"])/len(data))*100,'%')\n",
    "testing_data.to_dict(orient = \"records\")#orient若不设置，默认key值是数值\n",
    "test(testing_data,tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1=pd.read_csv(\"data\\zoo.data\",names=[\"animal_name\",\"hair\",\"feathers\",\"eggs\",\"milk\",\n",
    "                                       \"airbone\",\"aquatic\",\"predator\",\"toothed\",\"backbone\",\"breathes\",\"venomous\",\"fins\",\"legs\"\n",
    "                                       ,\"tail\",\"domestic\",\"catsize\",\"class\"])\n",
    "dataset1=dataset1.drop(\"animal_name\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80     3\n",
       "81     7\n",
       "82     4\n",
       "83     2\n",
       "84     1\n",
       "85     7\n",
       "86     4\n",
       "87     2\n",
       "88     6\n",
       "89     5\n",
       "90     3\n",
       "91     3\n",
       "92     4\n",
       "93     1\n",
       "94     1\n",
       "95     2\n",
       "96     1\n",
       "97     6\n",
       "98     1\n",
       "99     7\n",
       "100    2\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features=dataset1.iloc[:80,:-1]\n",
    "train_features\n",
    "test_features=dataset1.iloc[80:,:-1]\n",
    "train_targets=dataset1.iloc[:80,-1]\n",
    "test_targets=dataset1.iloc[80:,-1]\n",
    "test_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=6,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=4,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=DecisionTreeClassifier(criterion=\"entropy\",max_depth=6,min_samples_leaf=1,min_samples_split=4)#gini\n",
    "model.fit(train_features,train_targets)\n",
    "#Scikit-Learn 用的是 CART 算法， CART 算法仅产生二叉树：每一个非叶节点总是只有\n",
    "#两个子节点（只有是或否两个结果） 。然而，像 ID3 这样的算法可以产生超过两个子节，因此这里用sklearn没有python写的效果好\n",
    "#点的决策树模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction accuracy is: 80.95238095238095 %\n"
     ]
    }
   ],
   "source": [
    "prediction=model.predict(test_features)\n",
    "print(\"The prediction accuracy is:\",model.score(test_features,test_targets)*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn 中决策树的剪枝通过调参实现   \n",
    "clf = tree.DecisionTreeClassifier()这个构建决策树的构造函数，带有参数常用的包括如下：\n",
    "\n",
    "    criterion='gini', 选用基尼系数作为选择特征的分裂点“entropy”\n",
    "\n",
    "    max_depth=None, 树的最大深度\n",
    "\n",
    "    min_samples_split=2, 分裂点的样本个数\n",
    "\n",
    "    min_samples_leaf =1, 叶子节点的样本个数\n",
    "\n",
    "    max_leaf_nodes=None，最大的叶子节点数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction accuracy is: 76.19047619047619 %\n"
     ]
    }
   ],
   "source": [
    "### 试试随机森林\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model=RandomForestClassifier(n_estimators=5,max_leaf_nodes=6,n_jobs=-1,criterion=\"entropy\")\n",
    "model.fit(train_features,train_targets)\n",
    "prediction=model.predict(test_features)\n",
    "print(\"The prediction accuracy is:\",model.score(test_features,test_targets)*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction accuracy is: 80.95238095238095 %\n"
     ]
    }
   ],
   "source": [
    "### 试试ExtraTreesClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "model=ExtraTreesClassifier(n_estimators=5, max_depth=7,criterion=\"entropy\")\n",
    "model.fit(train_features,train_targets)\n",
    "prediction=model.predict(test_features)\n",
    "print(\"The prediction accuracy is:\",model.score(test_features,test_targets)*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction accuracy is: 85.71428571428571 %\n"
     ]
    }
   ],
   "source": [
    "### 试试AdaBoostClassifier（或者说Booting DTC，提升决策分类树）\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "model=AdaBoostClassifier(DecisionTreeClassifier(max_depth=3),n_estimators=200,algorithm=\"SAMME.R\",learning_rate=0.5)\n",
    "model.fit(train_features,train_targets)\n",
    "#model=AdaBoostClassifier(n_estimators=200,algorithm=\"SAMME.R\",learning_rate=0.5)#SAMME.R\n",
    "#model.fit(train_features,train_targets)\n",
    "prediction=model.predict(test_features)\n",
    "print(\"The prediction accuracy is:\",model.score(test_features,test_targets)*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction accuracy is: 85.71428571428571 %\n"
     ]
    }
   ],
   "source": [
    "### 试试Gradient Tree Boosting(梯度提升决策分类树也就是常说的GBDT（）)\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "model=GradientBoostingClassifier(max_depth=6,n_estimators=100,learning_rate=1)\n",
    "model.fit(train_features,train_targets)\n",
    "prediction=model.predict(test_features)\n",
    "print(\"The prediction accuracy is:\",model.score(test_features,test_targets)*100,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 连续属性值的处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于连续属性值取值数目不在有限，因此不能直接根据连续属性的可取值进行划分。最简单的是采用二分法对连续属性进行处理，这正是C4.5决策树算法中采用的机制.见西瓜书P83"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 回归树（Regression Tree）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果我们需要用树结构来做预测问题，比如使用属性房间数，地理位置来预测目标特征（target feature）即房屋价格，此时价格就是连续的。我们就需要使用回归树来解决这个问题。![pic1](pic1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回归树的生成与决策树生成基本一样，只是有两点改变，首先我们回顾一下决策树生成叶子节点时的停止准侧（标准critera）：  \n",
    "1.如果拆分过程导致数据集为空，则返回原始数据的目标特征值  \n",
    "2.如果拆分过程使得数据无特征剩余，则返回父节点的目标特征值  \n",
    "3.如果拆分过程使得数据目标特征值是一致时，返回这个值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.现在我们来考虑连续问题的情况，此时停止准则中的第三个点就不在适用，因为目标特征值是连续的，所以不可能拆分到一个纯的目标特征值.为了解决这个问题，我们可以使用一种个提前结束准则，即返回目标特征值的平均值，当拆分到数据集中数量小于等于5时.也就是在回归树中，我们采用平均目标特征值作为叶子结点（预测值）。注意这个5是可调的下面实验中我们将展示其影响"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.现在来考虑划分标准,我们希望通过这个划分标准划分得到的预测值，尽量靠近真实值，因此我们选取最小化加权方差(Varience)作为划分标准。为甚不用熵，因为目标特征值很多情况下就一个，那么条件熵是0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 举个例子"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pic4](pic4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$WeightVar(Season)=\\frac{1}{9}\\times(79-79)^2+\\frac{5}{9}\\times\\frac{(352-211.8)^2+(421-211.8)^2+(12-211.8)^2+(162-211.8)^2+(112-211.8)^2}{4}+\\frac{1}{9}\\times(161-161)^2+\\frac{2}{9}\\times\\frac{(109-137)^2+(165-137)^2}{1}=16429.1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$WeightVar(Weekday)=\\frac{2}{9}\\times\\frac{(109-94)^2+(79-94)^2}{1}+\\frac{2}{9}\\times\\frac{(162-137)^2+(112-137)^2}{1}+\\frac{1}{9}\\times(421-421)^2+\\frac{2}{9}\\times\\frac{(161-86.5)^2+(12-86.5)^2}{1}+\\frac{2}{9}\\times\\frac{(352-258.5)^2+(165-258.5)^2}{1}=6730$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$WeightVar(Weathersit)=\\frac{4}{9}\\times\\frac{(421-174.2)^2+(165-174.2)^2+(12-174.2)^2+(161-174.2)^2+(112-174.2)^2}{4}+\\frac{2}{9}\\times\\frac{(352-230.5)^2+(109-230.5)^2}{1}+\\frac{2}{9}\\times\\frac{(79-120.5)^2+(112-120.5)^2}{1}=19646.83$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于$Weekday$有最低的加权方差，因此选择这个特征作为根节点.![pic5](pic5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后准确度度量使用的是根均方误差RMSE：$$RMSE=\\sqrt{\\frac{\\sum_{i=1}^2(t_i-Model(test_i))^2}{n}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CART"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CART对分类树使用基尼指数最小化准则，进行特征选择，生成**二叉树**.**对于回归树采用平方误差最小化准则（没有使用RMSE）**由于CART生成二叉树，无论分类树还是回归树事实上对属性值选取采取的是二分法（连续属性处理方式）.(ID3,C45不一定生成二叉树)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CART分类树"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输入：训练数据集D，停止计算条件；  \n",
    "输出：CART决策树  \n",
    "(1) 设节点的训练数据集为$D$,对于每个特征$A$,对其可能的取的每个$a$值，计算$A=a$的基尼指数Gini(D,A=a).  \n",
    "(2) 在所有可能的特征以及它们所有可能的切分点$a$中，选择基尼指数最小的特征及其对应的切分点作为最优特征与最优切分点，生成两个子节点，并将数据集分配到两个子节点中。  \n",
    "(3) 对两个子节点递归调用(1),(2),直至满足停止条件  \n",
    "(4) 生成CART决策树  \n",
    "算法停止条件:节点中样本个数小于约定阈值，或样本集合的基尼指数小于预定阈值（样本基本属于同一类），或者没有更多特征."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CART回归树(最小二乘回归树)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CART回归树也叫最小二乘回归树，这是因为其以最小化平方误差来生成决策树的.其特征是采用二分法来选取的.**而且其目标特征值实际上采用的就是平均处理的方式.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于训练数据$$D=\\{(x_1,y_1),(x_2,y_2),..,(x_n,y_n)\\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一个回归树对应着输入空间(特征空间)的一个划分，以及在划分单元上的的输出值.假设将输入空间划分为$M$个单元$R_1,R_2,..,R_M$,并且在每个单元$R_m$上有一个固定输出值$c_m$,于是回归树模型可以表示为$$f(x)=\\sum_{m=1}^Mc_mI(x\\in R_m)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那么这个回归树的误差可以表示$$\\sum_{i=1}^n(y_i-c_i)^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中$c_i=f(x)\\in\\{c_1,c_2,...,c_M\\}$,由于回归树生成是最小平方误差，所以$c_m$应该是单元$R_m$中的所有输入实例$x_i$对应的标签值$y_i$的均值，即$$\\hat{c}_m=c_m=ave(y_i|x_i\\in R_m)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这和上面讲的平均目标特征值作为叶子结点的处理方式是一样的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "特征空间的划分采用启发式的方法,选择第$j$个变量（特征）和它的取值$s$，作为切分变量和切分点，将数据集划分为两个.寻找最优切分变量和切分点通过最小化平方差.具体见算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CART回归树(最小二乘回归树)算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输入:训练数据集$D$；  \n",
    "输出：回归树$f(x)$   \n",
    "在训练数据集所在的输入空间中，递归地将每个区域划分为两个子区域，并决定每个子区域上的输出值，构建二叉树   \n",
    "(1)选择最优切分变量(特征)$j$与切分点$s$，求解$$min_{j,s}[min_{c_1}\\sum_{x_i\\in R_1(j,s)}(y_i-c_1)^2+min_{c_2}\\sum_{x_i\\in R_2(j,s)}(y_i-c_2)^2]$$遍历变量$j$，对固定切分变量扫描切分点$s$,选择使上式达到最小值得$(j,s)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2)用选定的对(j,s)划分区域，并决定相应的输出值：$$R_1(j,s)=\\{x|x^{j}\\leq s\\},R_2(j,s)=\\{x|x^{j}>s\\}$$\n",
    "$$\\hat{c}_m=\\frac{1}{N_m}\\sum_{x_i\\in R_m(j,s)y_i},x\\in R_m,m=1,2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3)继续对两个子区域调用(1),(2),直至满足停止条件.  \n",
    "(4)将输入空间划分为$M$个区域$R_1,R_2,...,R_M$,生成决策树:$$f(x)=\\sum_{m=1}^M\\hat{c}_mI(x\\in R_m)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sklearn实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>642</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>7328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     season  holiday  weekday  workingday  weathersit   cnt\n",
       "642       4        0        4           1           2  7328\n",
       "687       4        0        0           0           1  4669\n",
       "236       3        0        4           1           2  3542\n",
       "93        2        0        1           1           1  3115\n",
       "246       3        0        0           0           1  4940"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "dataset=pd.read_csv(\"data/Bike-Sharing-Dataset/day.csv\")\n",
    "dataset=dataset[['season','holiday','weekday','workingday','weathersit','cnt']].sample(frac=1)\n",
    "#dataset.sample(frac=0.11)#随机抽取，参数frac：0-1之间，表示随机抽取比例，想抽取n个则直接设置参数n=2\n",
    "#dataset.sample(n=5)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4504.3488372093025"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_data=np.mean(dataset.iloc[:,-1])#对最后一列取个平均\n",
    "mean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(dataset):\n",
    "    training_data=dataset.iloc[:int(0.7*len(dataset))].reset_index(drop=True)#drop index并重新设置\n",
    "    testing_data=dataset.iloc[int(0.7*len(dataset)):].reset_index(drop=True)\n",
    "    return training_data,testing_data\n",
    "training_data=train_test_split(dataset)[0]\n",
    "testing_data=train_test_split(dataset)[1]\n",
    "#training_data\n",
    "#testing_data.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=5,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression_model=DecisionTreeRegressor(criterion=\"mse\",min_samples_leaf=5)\n",
    "regression_model.fit(training_data.iloc[:,:-1],training_data.iloc[:,-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted=regression_model.predict(testing_data.iloc[:,:-1])\n",
    "predicted.shape\n",
    "testing_data.iloc[:,-1:].shape\n",
    "test_target=np.asarray(testing_data.iloc[:,-1:])\n",
    "test_target=test_target.reshape([220,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1495.8062812976875"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE=np.sqrt(np.sum((predicted-test_target)**2)/(len(test_target)-1))\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 现在我们看看：拆分数据集最小量变化对树结构的影响"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-4680c5a14db8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtrain_data_RMSE\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtest_data_RMSE\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtrain_target\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mtest_taregt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtesting_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtesting_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as pl\n",
    "train_data_RMSE=[]\n",
    "test_data_RMSE=[]\n",
    "train_target=np.asarray(training_data.iloc[:,-1:]).reshape([len(training_data),])\n",
    "test_taregt=np.asarray(testing_data.iloc[:,-1:]).reshape([len(testing_data,)])\n",
    "for i in range(1,100):\n",
    "    model=DecisionTreeRegressor(criterion=\"mse\",min_samples_leaf=i)\n",
    "    model.fit(training_data.iloc[:,:-1],training_data.iloc[:,-1:])\n",
    "    train_predict=model.predict(training_data.iloc[:,:-1])\n",
    "    test_predict=model.predict(testing_data.iloc[:,:-1])\n",
    "    train_rmse=np.sqrt(np.sum((train_predict-train_target)**2)/(len(training_data)-1))\n",
    "    test_rmse=np.sqrt(np.sum((test_predict-test_target)**2)/(len(testing_data-1)))\n",
    "    train_data_RMSE.append(train_rmse)\n",
    "    test_data_RMSE.append(test_rmse)\n",
    "pl.plot(range(1,100),train_data_RMSE,label=\"train_data_RMSE\")#也就是两条线相交的那个点是最好的\n",
    "pl.plot(range(1,100),test_data_RMSE,label=\"test_data_RMSE\")\n",
    "pl.legend()\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 看看线性模型在此数据集上的表现："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=True)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model=LinearRegression(normalize=True)\n",
    "model.fit(training_data.iloc[:,:-1],training_data.iloc[:,-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31823.72787200696\n"
     ]
    }
   ],
   "source": [
    "predicted=model.predict(testing_data.iloc[:,:-1])\n",
    "RMSE=np.sqrt(np.sum((predicted-test_target)**2)/(len(testing_data)-1))\n",
    "print(RMSE)#发现方差更大，可能是因为数据并非是非线性的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=0.3, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=True, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#再试试Lasso和Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "model=Lasso(alpha=0.3,normalize=True)\n",
    "model.fit(training_data.iloc[:,:-1],training_data.iloc[:,-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1704.4323767882483\n"
     ]
    }
   ],
   "source": [
    "predicted=model.predict(testing_data.iloc[:,:-1])\n",
    "RMSE=np.sqrt(np.sum((predicted-test_target)**2)/(len(testing_data)-1))\n",
    "print(RMSE)#发现方差更大，可能是因为数据并非是非线性的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=0.3, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=True, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#再试试Ridge\n",
    "from sklearn.linear_model import Ridge\n",
    "model=Ridge(0.3,normalize=True)\n",
    "model.fit(training_data.iloc[:,:-1],training_data.iloc[:,-1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30459.106282983088\n"
     ]
    }
   ],
   "source": [
    "predicted=model.predict(testing_data.iloc[:,:-1])\n",
    "RMSE=np.sqrt(np.sum((predicted-test_target)**2)/(len(testing_data)-1))\n",
    "print(RMSE)#发现方差更大，可能是因为数据并非是非线性的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1469.981800167609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "###再试试随机回归森林\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model=RandomForestRegressor(max_depth=3,n_estimators=100)#没有指出base_estimator,则默认是DecisionTreeRegressor(max_depth=3)\n",
    "model.fit(training_data.iloc[:,:-1],training_data.iloc[:,-1:])\n",
    "predicted=model.predict(testing_data.iloc[:,:-1])\n",
    "RMSE=np.sqrt(np.sum((predicted-test_target)**2)/(len(testing_data)-1))\n",
    "print(RMSE)#发现方差更大，可能是因为数据并非是非线性的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1452.7949585950248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "###再试试极致随机森林\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "model=ExtraTreesRegressor(max_depth=4,n_estimators=100)#没有指出base_estimator,则默认是DecisionTreeRegressor(max_depth=3)\n",
    "model.fit(training_data.iloc[:,:-1],training_data.iloc[:,-1:])\n",
    "predicted=model.predict(testing_data.iloc[:,:-1])\n",
    "RMSE=np.sqrt(np.sum((predicted-test_target)**2)/(len(testing_data)-1))\n",
    "print(RMSE)#发现方差更大，可能是因为数据并非是非线性的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1489.9645036711295\n"
     ]
    }
   ],
   "source": [
    "### 再试试AdaBoosting regression（提升回归树）\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "model=AdaBoostRegressor(base_estimator=DecisionTreeRegressor(max_depth=3),n_estimators=100,learning_rate=1)#没有指出base_estimator,则默认是DecisionTreeRegressor(max_depth=3)\n",
    "model.fit(training_data.iloc[:,:-1],training_data.iloc[:,-1:])\n",
    "predicted=model.predict(testing_data.iloc[:,:-1])\n",
    "RMSE=np.sqrt(np.sum((predicted-test_target)**2)/(len(testing_data)-1))\n",
    "print(RMSE)#发现方差更大，可能是因为数据并非是非线性的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1457.8397965240779\n"
     ]
    }
   ],
   "source": [
    "### 再试试Gradient Boosting Tree Regressor（梯度提升回归树）\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "model=GradientBoostingRegressor(loss=\"huber\",max_depth=2,n_estimators=200,learning_rate=0.05)#由于使用梯度，所以学习率更小，损失函数可选有ls,lad,huber,quamtile\n",
    "model.fit(training_data.iloc[:,:-1],training_data.iloc[:,-1:])\n",
    "predicted=model.predict(testing_data.iloc[:,:-1])\n",
    "RMSE=np.sqrt(np.sum((predicted-test_target)**2)/(len(testing_data)-1))\n",
    "print(RMSE)#发现方差更大，可能是因为数据并非是非线性的"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
